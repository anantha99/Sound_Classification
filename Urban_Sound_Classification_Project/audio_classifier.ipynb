{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1UEE3Zau2eXSYUsmjx-n93YpROsUiTsJM",
      "authorship_tag": "ABX9TyN/q0ZGGiJTgM9w//Ja97TY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anantha99/Sound_Classification/blob/main/audio_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading the data"
      ],
      "metadata": {
        "id": "3G3zaUxmsYKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. We used a opendatasets library from jovian to load the dataset from the source. \n",
        "2. We have unzipped the tar file and extracted all the contents of the file.\n",
        "3. We removed the file named '.DS_Store' in each of the dataset folder which is threat to the system.\n",
        "\n"
      ],
      "metadata": {
        "id": "NUjZNlRTxv6f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZLTxHecTn6V",
        "outputId": "4f5db70c-7936-4625-a947-ef293b733f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.64.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (6.1.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2022.6.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "#importing the dataset\n",
        "!pip install opendatasets --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "dataset_url = 'https://goo.gl/8hY5ER'\n",
        "od.download(dataset_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UoUq8SOUyOf",
        "outputId": "bb15fc92-757d-40af-9de9-415cd13b2adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://goo.gl/8hY5ER to ./UrbanSound8K.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6023749632it [1:10:06, 1432064.56it/s]                                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# importing the \"tarfile\" module\n",
        "import tarfile\n",
        "  \n",
        "# open file\n",
        "file = tarfile.open('/content/UrbanSound8K.tar.gz')\n",
        "  \n",
        "# extracting file\n",
        "file.extractall('./content/')\n",
        "  \n",
        "file.close()"
      ],
      "metadata": {
        "id": "2OVgTtx8jare"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removed all the .DS_Store files in the dataset \n",
        "import os \n",
        "\n",
        "dataset_path = '/content/content/UrbanSound8K/audio'\n",
        "for dirpath, dirnames, filenames in os.walk(dataset_path):\n",
        "  #ensure we are not at the root level\n",
        "  file = []\n",
        "  if dirpath is not dataset_path:\n",
        "    for f in filenames:\n",
        "      #print(f)\n",
        "      if f == '.DS_Store':\n",
        "        path_of_the_file = os.path.join(dirpath,f)\n",
        "        os.remove(path_of_the_file)\n",
        "      else:\n",
        "        #loading the labels\n",
        "        filename_components = f.split(\"-\")\n",
        "        print(filename_components)\n",
        "        label_component = filename_components[1]\n",
        "        file.append(label_component)"
      ],
      "metadata": {
        "id": "x-MkAAzwjbbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing "
      ],
      "metadata": {
        "id": "ybqVRX4lS6f3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Data Preprocessing **\n",
        "1. It is the process of conversion of raw data into numerical features theat can be processed while preserving the original information.\n",
        "2. Since the data is audio which is collected in the analog form it should be converted into digital form and then analyzed for features.\n",
        "\n",
        "1. We saw in the EDA part that each signal had different\n",
        "  1. Bit_depth\n",
        "  2. Sample Rate \n",
        "  3. Coverting everything to mono.\n",
        "2. We can use librosa librbary which will help us overcome all the above points.For much of the preprocessing we will be able to use Librosa’s load() function, which by default converts the sampling rate to 22.05 KHz, normalise the data so the bit-depth values range between -1 and 1 and flattens the audio channels into mono.\n",
        "** Feature Extraction **\n",
        "3. Now we have to extract the features. We have to convert them into visual representation which will allow us to indentify features for classification.\n",
        "For doing this there are popularly 2 methods:\n",
        "  1. MFCC -  Mel-Frequency Cepstral Coefficients  \n",
        "  2. Spectrograms\n",
        "\n",
        "Spectrograms are a useful technique for visualising the spectrum of frequencies of a sound and how they vary during a very short period of time.\n",
        "\n",
        "But spectrograms does not take into consideration the quality of the same sound. So we make use mfcc which are much more sensitive and here mfcc uses quasi-logarithmic spaced frequency scale, which is more similar to how the human auditory system processes sounds.\n",
        "\n",
        "For each audio file in the dataset, we will extract an MFCC (meaning we have an image representation for each audio sample) and store it in a Panda Dataframe along with it’s classification label. For this we will use Librosa’s mfcc() function which generates an MFCC from time series audio data."
      ],
      "metadata": {
        "id": "ycc9Wb9Fyo8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import math\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "DATASET_PATH = '/content/content/UrbanSound8K/audio'\n",
        "\n",
        "\n",
        "\n",
        "def save_mfcc(dataset_path,num_mfcc=40):\n",
        "    # dictionary to store mapping, labels, and MFCCs\n",
        "    extracted_features = []\n",
        "    for dirpath, dirnames, filenames in os.walk(dataset_path):\n",
        "        #ensure we are not at the root level\n",
        "        if dirpath is not dataset_path:\n",
        "            #save the fold number\n",
        "            dirpath_components = dirpath.split(os.sep)\n",
        "            semantic_label = dirpath_components[-1]\n",
        "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
        "\n",
        "            #process files for a specific genre\n",
        "            for f in filenames:\n",
        "                #loading the labels \n",
        "                filename_components = f.split(\"-\")\n",
        "                label_component = filename_components[1]\n",
        "                #load audio files \n",
        "                file_path = os.path.join(dirpath, f)\n",
        "                #loading the file using librosa\n",
        "                signal , sr = librosa.load(file_path)\n",
        "                #extract the mfcc features\n",
        "                mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=num_mfcc).T,axis=0)\n",
        "\n",
        "                #store the mfcc for segment if it has expected length\n",
        "                #mapping_component = data['mapping']\n",
        "                extracted_features.append([mfcc,label_component,semantic_label])\n",
        "    return extracted_features       \n",
        "                    \n",
        "extracted_values = save_mfcc(DATASET_PATH)\n"
      ],
      "metadata": {
        "id": "AmLYvHoLS-9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f78eb52-7188-43b2-e7b4-c5b4b03708fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: fold10\n",
            "\n",
            "Processing: fold4\n",
            "\n",
            "Processing: fold3\n",
            "\n",
            "Processing: fold1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
            "  n_fft, y.shape[-1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: fold2\n",
            "\n",
            "Processing: fold9\n",
            "\n",
            "Processing: fold7\n",
            "\n",
            "Processing: fold6\n",
            "\n",
            "Processing: fold8\n",
            "\n",
            "Processing: fold5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save as csv"
      ],
      "metadata": {
        "id": "2oi2UBJzjJYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values = extracted_values.copy()"
      ],
      "metadata": {
        "id": "VdYdnjxNSVXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting arrays to list before putting saving it as a csv\n",
        "for j in values:\n",
        "  j[0] = j[0].tolist()"
      ],
      "metadata": {
        "id": "nmrCGcdbTdbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_csv=pd.DataFrame(values,columns=['feature','class','fold_component'])"
      ],
      "metadata": {
        "id": "VG4JxZ8hV_nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_csv.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "M2GxX5oSWZ4b",
        "outputId": "589194a0-84b8-49e0-a8a4-be32a83e7c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             feature class fold_component\n",
              "0  [-197.47579956054688, 173.50418090820312, -26....     9         fold10\n",
              "1  [-322.86224365234375, 139.29617309570312, -10....     3         fold10\n",
              "2  [52.46525192260742, 114.9016342163086, -16.365...     5         fold10\n",
              "3  [-223.27256774902344, 70.83647155761719, -44.8...     3         fold10\n",
              "4  [-112.69658660888672, 128.1402587890625, -44.6...     4         fold10"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc6cb6bf-1def-446f-b513-22c306dd089c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>class</th>\n",
              "      <th>fold_component</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-197.47579956054688, 173.50418090820312, -26....</td>\n",
              "      <td>9</td>\n",
              "      <td>fold10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-322.86224365234375, 139.29617309570312, -10....</td>\n",
              "      <td>3</td>\n",
              "      <td>fold10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[52.46525192260742, 114.9016342163086, -16.365...</td>\n",
              "      <td>5</td>\n",
              "      <td>fold10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-223.27256774902344, 70.83647155761719, -44.8...</td>\n",
              "      <td>3</td>\n",
              "      <td>fold10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-112.69658660888672, 128.1402587890625, -44.6...</td>\n",
              "      <td>4</td>\n",
              "      <td>fold10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc6cb6bf-1def-446f-b513-22c306dd089c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc6cb6bf-1def-446f-b513-22c306dd089c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc6cb6bf-1def-446f-b513-22c306dd089c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the file to csv \n",
        "save_csv.to_csv('extracted_data.csv')"
      ],
      "metadata": {
        "id": "gbl-w5qZWZZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#copying the file to google drive\n",
        "!cp extracted_data.csv /content/drive/MyDrive/audio_data"
      ],
      "metadata": {
        "id": "w2lA1auPW3yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MCrmwUsPZAXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Data"
      ],
      "metadata": {
        "id": "h2sozbIKjRVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ast import literal_eval\n",
        "\n",
        "#extracted_features_df=pd.DataFrame(extracted_values,columns=['feature','class','fold_component'])\n",
        "#inplace of literal_eval pd.val can also be used but this is 15X faster \n",
        "extracted_features_df = pd.read_csv('/content/drive/MyDrive/audio_data/extracted_data.csv',converters={'feature': literal_eval})"
      ],
      "metadata": {
        "id": "jyEqv8e3ano-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_features_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9dQnPd5Zhve",
        "outputId": "0779d8d3-83ce-40bd-8ff9-56a574ad6786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'feature', 'class', 'fold_component'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_features_df.drop(['Unnamed: 0'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "TgUjFEfZZz4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_features_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t-JWmU0a6ua",
        "outputId": "1a759006-1ee2-474c-b491-e49d5154dc17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8732, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#replacing class numbers with their class names\n",
        "extracted_features_df['class'] = extracted_features_df['class'].map({0:'air_conditioner',\n",
        "                               1:'car_horn',\n",
        "                               2:'children_playing',\n",
        "                               3:'dog_bark',\n",
        "                               4:'drilling',\n",
        "                               5:'engine_idling',\n",
        "                               6:'gun_shot',\n",
        "                               7:'jackhammer',\n",
        "                               8:'siren',\n",
        "                               9:'street_music'})"
      ],
      "metadata": {
        "id": "nEazzLSmPa3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_features_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IiKRHDFSj76o",
        "outputId": "ab313934-78b4-470f-c06b-ac1ff8c6ed49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             feature          class  \\\n",
              "0  [-197.47579956054688, 173.50418090820312, -26....   street_music   \n",
              "1  [-322.86224365234375, 139.29617309570312, -10....       dog_bark   \n",
              "2  [52.46525192260742, 114.9016342163086, -16.365...  engine_idling   \n",
              "3  [-223.27256774902344, 70.83647155761719, -44.8...       dog_bark   \n",
              "4  [-112.69658660888672, 128.1402587890625, -44.6...       drilling   \n",
              "\n",
              "  fold_component  \n",
              "0         fold10  \n",
              "1         fold10  \n",
              "2         fold10  \n",
              "3         fold10  \n",
              "4         fold10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00ed0853-cc48-4eb3-b626-fc48af38a540\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>class</th>\n",
              "      <th>fold_component</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-197.47579956054688, 173.50418090820312, -26....</td>\n",
              "      <td>street_music</td>\n",
              "      <td>fold10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-322.86224365234375, 139.29617309570312, -10....</td>\n",
              "      <td>dog_bark</td>\n",
              "      <td>fold10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[52.46525192260742, 114.9016342163086, -16.365...</td>\n",
              "      <td>engine_idling</td>\n",
              "      <td>fold10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-223.27256774902344, 70.83647155761719, -44.8...</td>\n",
              "      <td>dog_bark</td>\n",
              "      <td>fold10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-112.69658660888672, 128.1402587890625, -44.6...</td>\n",
              "      <td>drilling</td>\n",
              "      <td>fold10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00ed0853-cc48-4eb3-b626-fc48af38a540')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00ed0853-cc48-4eb3-b626-fc48af38a540 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00ed0853-cc48-4eb3-b626-fc48af38a540');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Split the dataset into independent and dependent dataset\n",
        "import numpy as np\n",
        "X=np.array(extracted_features_df['feature'].tolist())\n",
        "y=np.array(extracted_features_df['class'].tolist())"
      ],
      "metadata": {
        "id": "ekG0gnEaPa1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxb7Pmghd9nH",
        "outputId": "ef4edad2-71f9-4087-ed1e-5807e0cc2027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.97475800e+02,  1.73504181e+02, -2.65719948e+01, ...,\n",
              "         8.78134146e-02, -3.71990299e+00, -2.50093222e+00],\n",
              "       [-3.22862244e+02,  1.39296173e+02, -1.09721375e+01, ...,\n",
              "         1.35880268e+00,  1.79998529e+00,  3.27832818e+00],\n",
              "       [ 5.24652519e+01,  1.14901634e+02, -1.63653412e+01, ...,\n",
              "         2.37140274e+00,  1.70572448e+00,  1.62329721e+00],\n",
              "       ...,\n",
              "       [-3.04419220e+02,  1.25434494e+02, -9.40262508e+00, ...,\n",
              "        -4.17565250e+00, -4.94980812e+00, -5.25423670e+00],\n",
              "       [-1.83269470e+02,  4.05924149e+01,  3.99460258e+01, ...,\n",
              "         3.55715251e+00, -9.44424248e+00, -9.55445766e-02],\n",
              "       [-1.69769165e+02,  1.01184067e+02, -1.14349079e+01, ...,\n",
              "         3.00564480e+00, -6.44474649e+00,  2.53110313e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y=np.array(pd.get_dummies(y))\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "q869cUKDLCp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelencoder = LabelEncoder()\n",
        "y = to_categorical(labelencoder.fit_transform(y))\n"
      ],
      "metadata": {
        "id": "8GwPGWhWTHSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN4Bly-VTVlf",
        "outputId": "6d411890-40ab-40e3-bc5c-932f939114eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8732, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTlnkFmHPayI",
        "outputId": "0ff3f0b5-f3f8-4702-f639-4c22db735be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8732, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Creation "
      ],
      "metadata": {
        "id": "-nqaYZVoLkDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "pWCvw_KHPasT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAxtlUeBUB54",
        "outputId": "9500ebad-4597-47e6-a1a0-acf3c86ee5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6985, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h33-okQ7aub",
        "outputId": "3348a28f-456c-429c-9a5c-82dec10bf6d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-4.85112976e+02,  1.18378418e+02, -2.37864742e+01,  4.47219391e+01,\n",
              "        8.44127083e+00,  2.11784573e+01,  1.26236734e+01,  1.11395464e+01,\n",
              "        9.40762615e+00,  1.20282135e+01, -2.23583817e+00,  1.01117783e+01,\n",
              "       -2.37149167e+00,  3.93047810e+00, -3.79374695e+00,  7.69953918e+00,\n",
              "       -8.74187499e-02,  9.65779591e+00, -5.78604126e+00,  3.88852501e+00,\n",
              "       -6.16443348e+00,  6.70675325e+00, -6.48489141e+00,  5.31670380e+00,\n",
              "       -4.36563635e+00,  1.34347749e+00, -4.65915489e+00,  2.13763380e+00,\n",
              "       -2.72958136e+00,  2.31922460e+00, -2.75978947e+00,  2.43736053e+00,\n",
              "       -5.51829910e+00,  2.57631898e+00, -3.82228613e+00,  1.42204297e+00,\n",
              "       -2.07691550e+00,  2.26053429e+00, -3.69663835e+00,  2.26473510e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "tt9XU12PPajb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235a461e-303b-42f4-ab2f-97a353a6daab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "yeQ4ttbnFCWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8qoWpuqJ5xj",
        "outputId": "9969f1a2-8ca2-4176-923e-a7b11856fe29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8732, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### No of classes\n",
        "num_labels=y.shape[1]"
      ],
      "metadata": {
        "id": "vpXJaT-6Jwvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "###first layer\n",
        "model.add(Dense(100,input_shape=(40,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "###second layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "###final layer\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "rFAFNjkbJ_qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlVJiU9AKJhr",
        "outputId": "736b3b1e-b8dd-4428-e6fc-55edbc7a00c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 100)               4100      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 100)               0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,210\n",
            "Trainable params: 15,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',metrics=['accuracy'],loss='categorical_crossentropy')"
      ],
      "metadata": {
        "id": "Wh3-DpQvKNAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Trianing my model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime \n",
        "\n",
        "num_epochs = 20\n",
        "num_batch_size = 32\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification_1.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6CM25VOLaaV",
        "outputId": "04e27375-1e9d-4cc6-f7c0-862e4de7165c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "202/219 [==========================>...] - ETA: 0s - loss: 0.2796 - accuracy: 0.9021\n",
            "Epoch 1: val_loss improved from inf to 0.36380, saving model to saved_models/audio_classification_1.hdf5\n",
            "219/219 [==============================] - 1s 4ms/step - loss: 0.2768 - accuracy: 0.9026 - val_loss: 0.3638 - val_accuracy: 0.9021\n",
            "Epoch 2/20\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2762 - accuracy: 0.9022\n",
            "Epoch 2: val_loss did not improve from 0.36380\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2767 - accuracy: 0.9025 - val_loss: 0.4004 - val_accuracy: 0.8844\n",
            "Epoch 3/20\n",
            "203/219 [==========================>...] - ETA: 0s - loss: 0.2762 - accuracy: 0.9015\n",
            "Epoch 3: val_loss did not improve from 0.36380\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2756 - accuracy: 0.9019 - val_loss: 0.3814 - val_accuracy: 0.8890\n",
            "Epoch 4/20\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2577 - accuracy: 0.9059\n",
            "Epoch 4: val_loss did not improve from 0.36380\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2566 - accuracy: 0.9074 - val_loss: 0.3764 - val_accuracy: 0.8918\n",
            "Epoch 5/20\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2670 - accuracy: 0.9070\n",
            "Epoch 5: val_loss did not improve from 0.36380\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2700 - accuracy: 0.9065 - val_loss: 0.3822 - val_accuracy: 0.8975\n",
            "Epoch 6/20\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.2631 - accuracy: 0.9097\n",
            "Epoch 6: val_loss did not improve from 0.36380\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2641 - accuracy: 0.9098 - val_loss: 0.3717 - val_accuracy: 0.8935\n",
            "Epoch 7/20\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.2720 - accuracy: 0.9041\n",
            "Epoch 7: val_loss did not improve from 0.36380\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2656 - accuracy: 0.9069 - val_loss: 0.3876 - val_accuracy: 0.8924\n",
            "Epoch 8/20\n",
            "199/219 [==========================>...] - ETA: 0s - loss: 0.2422 - accuracy: 0.9171\n",
            "Epoch 8: val_loss did not improve from 0.36380\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2404 - accuracy: 0.9184 - val_loss: 0.3754 - val_accuracy: 0.8947\n",
            "Epoch 9/20\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2564 - accuracy: 0.9090\n",
            "Epoch 9: val_loss improved from 0.36380 to 0.35989, saving model to saved_models/audio_classification_1.hdf5\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2577 - accuracy: 0.9084 - val_loss: 0.3599 - val_accuracy: 0.8952\n",
            "Epoch 10/20\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.2534 - accuracy: 0.9121\n",
            "Epoch 10: val_loss did not improve from 0.35989\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2542 - accuracy: 0.9111 - val_loss: 0.3762 - val_accuracy: 0.8947\n",
            "Epoch 11/20\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2547 - accuracy: 0.9138\n",
            "Epoch 11: val_loss did not improve from 0.35989\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2535 - accuracy: 0.9142 - val_loss: 0.3674 - val_accuracy: 0.9004\n",
            "Epoch 12/20\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2461 - accuracy: 0.9143\n",
            "Epoch 12: val_loss did not improve from 0.35989\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2450 - accuracy: 0.9140 - val_loss: 0.3635 - val_accuracy: 0.9033\n",
            "Epoch 13/20\n",
            "215/219 [============================>.] - ETA: 0s - loss: 0.2508 - accuracy: 0.9134\n",
            "Epoch 13: val_loss did not improve from 0.35989\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2514 - accuracy: 0.9131 - val_loss: 0.3626 - val_accuracy: 0.9015\n",
            "Epoch 14/20\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2348 - accuracy: 0.9188\n",
            "Epoch 14: val_loss did not improve from 0.35989\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2362 - accuracy: 0.9183 - val_loss: 0.4006 - val_accuracy: 0.8792\n",
            "Epoch 15/20\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2545 - accuracy: 0.9115\n",
            "Epoch 15: val_loss did not improve from 0.35989\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2542 - accuracy: 0.9114 - val_loss: 0.3679 - val_accuracy: 0.8924\n",
            "Epoch 16/20\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.2324 - accuracy: 0.9183\n",
            "Epoch 16: val_loss improved from 0.35989 to 0.34503, saving model to saved_models/audio_classification_1.hdf5\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2328 - accuracy: 0.9185 - val_loss: 0.3450 - val_accuracy: 0.9061\n",
            "Epoch 17/20\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2225 - accuracy: 0.9213\n",
            "Epoch 17: val_loss did not improve from 0.34503\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2242 - accuracy: 0.9207 - val_loss: 0.3601 - val_accuracy: 0.9044\n",
            "Epoch 18/20\n",
            "206/219 [===========================>..] - ETA: 0s - loss: 0.2158 - accuracy: 0.9204\n",
            "Epoch 18: val_loss did not improve from 0.34503\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2180 - accuracy: 0.9198 - val_loss: 0.3634 - val_accuracy: 0.9027\n",
            "Epoch 19/20\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.2411 - accuracy: 0.9196\n",
            "Epoch 19: val_loss did not improve from 0.34503\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2445 - accuracy: 0.9177 - val_loss: 0.3509 - val_accuracy: 0.8993\n",
            "Epoch 20/20\n",
            "204/219 [==========================>...] - ETA: 0s - loss: 0.2307 - accuracy: 0.9217\n",
            "Epoch 20: val_loss did not improve from 0.34503\n",
            "219/219 [==============================] - 1s 3ms/step - loss: 0.2299 - accuracy: 0.9213 - val_loss: 0.3624 - val_accuracy: 0.9067\n",
            "Training completed in time:  0:00:20.527126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_accuracy = model.evaluate(X_train,y_train,verbose=0)\n",
        "print(\"Training Accuracy:\",training_accuracy[1])\n",
        "\n",
        "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(\"Testing_accuracy:\",test_accuracy[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jfxYZkhXnlu",
        "outputId": "cd2ad73a-d268-4854-fa0c-2495bc4fb4e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.972655713558197\n",
            "Testing_accuracy: 0.9066972136497498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "3-OYfNsTu64h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting mfcc values from the given waves\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def features_extractor(file_name):\n",
        "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "    \n",
        "    return mfccs_scaled_features"
      ],
      "metadata": {
        "id": "4sOr_jUlmR2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a function that predicts the class taking the file name\n",
        "def predict_class(file_name, model_name):\n",
        "  mfccs_scaled_features = features_extractor(file_name)\n",
        "  mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "  #print(mfccs_scaled_features.shape)\n",
        "  predicted_label=np.argmax(model_name.predict(mfccs_scaled_features,verbose=0), axis=-1)\n",
        "  print(model_name.predict(mfccs_scaled_features,verbose=0))\n",
        "  prediction_class = labelencoder.inverse_transform(predicted_label) \n",
        "  return prediction_class[0]\n"
      ],
      "metadata": {
        "id": "QBR1lrFTtJkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_class('/content/drive/MyDrive/audio_data/drilling_sound.wav',model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4310smvttQS",
        "outputId": "0b399edd-d562-49c8-ff9d-f1dbc7ba041d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.7306638e-12 1.2583318e-07 1.1102114e-05 2.1251966e-05 2.7124744e-10\n",
            "  9.9994159e-01 5.2374498e-12 2.5314475e-12 1.1015914e-09 2.5993919e-05]]\n",
            "engine_idling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the Model and Reusing the weights."
      ],
      "metadata": {
        "id": "hPkwLgezwBqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model_load = load_model('/content/drive/MyDrive/audio_data/audio_classification_1.hdf5')"
      ],
      "metadata": {
        "id": "ILSlfSrTwH07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_load.summary()"
      ],
      "metadata": {
        "id": "CUkfTyiFwd3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f48aef-ecf6-46e4-b086-46608b63ba08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 100)               4100      \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 100)               0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 100)               0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,210\n",
            "Trainable params: 15,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_class('/content/dog bark.wav',model_load))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8MdwKg5w7AQ",
        "outputId": "cae2849b-39e7-4cf7-d84a-8aa8098f5ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0703705e-22 4.9438430e-18 9.8636672e-12 1.0000000e+00 1.9900571e-16\n",
            "  6.3682492e-14 9.1150010e-10 1.7017466e-21 8.4906711e-14 9.4310974e-12]]\n",
            "dog_bark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp saved_models/audio_classification_1.hdf5 /content/drive/MyDrive/audio_data/"
      ],
      "metadata": {
        "id": "dWxA9BIMxC9Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}